---
layout: post
title: KU Leuven Dataset
subtitle: 
cover-img: /assets/img/28.PNG
thumbnail-img: /assets/img/28.PNG
share-img: 
tags:
---

The KU Leuven (KUL) dataset targets a residential complex. The site (100m x 60m) is comprised of an underground parking and three apartment buildings. The documentation only includes the parking (PRK) and one of the appartments (BUH).

![site1.PNG](../assets/img/testcase_progress1.PNG)

The IFC models contain the structure phase of the construction process. This includes structural elements such as slabs, walls, staircases and so on. In total 2621 elements are present.

![42.PNG](../assets/img/42.PNG)

<video controls autoplay>        <source src="../assets/video/KUL_small.mp4" type="video/mp4">        Your browser does not support the video tag.    </video>

The site was document twoweekly for a total of 17 measurement epochs. A combination of UAV flights (DJI phantom 4), Lidar measurements (LeicaP30 and BLK) and handheld-images (CANON EOS 5D MarkII) were captured.

![40.PNG](../assets/img/40.PNG)

<video controls autoplay>        <source src="../assets/video/KUL-TLS.mp4" type="video/mp4">        Your browser does not support the video tag.    </video><video controls autoplay>        <source src="../assets/video/KUL-UAV.mp4" type="video/mp4">        Your browser does not support the video tag.    </video><video controls autoplay>        <source src="../assets/video/KUL-IMG.mp4" type="video/mp4">        Your browser does not support the video tag.    </video>




.

Did you know we were only able to align 65% of the imagery on the Construction sites using commercial software ([MetaShape](https://www.agisoft.com/) and [RealityCapture](https://www.capturingreality.com/))? This is not so surprising if you know the many obstacles [**Structure-from-Motion**](https://en.wikipedia.org/wiki/Structure_from_motion) have to overcome to allign the imagery below.



In this competition, we want to spark innovation for more robust alignment procedures. This includes both the interior and exterior camera parameters. As an example, you can take a look at what information is stored from a software like [RealityCapture](https://www.capturingreality.com/)

![38.PNG](../assets/img/38.PNG)

Given these parameters, we can accurately position the camera sensors in the construction cordinate system. Using the [GEOMAPI](https://https://geomatics.pages.gitlab.kuleuven.be/research-projects/geomapi/) API, we can easily import some imagery and point clouds (take a look at our website for more examples).

```
import geomapi
from geomapi import tools as tl
from geomapi.utils import geometryutils as gmu

imgNodes=tl.xml_to_nodes(path_to_metashape_xml)

las= laspy.read(las_path)
pcdNode=PointCloudNode(name='myPointCloud', resource=gmu.las_to_pcd(las))
```

And we can visualize these resources using Open3D and some placeholder geometries for the imagery. Note that merging geometries before sending them to the visualizer significantly speeds up the rendering.

```
joinedImages=gmu.join_geometries([gmu.generate_visual_cone_from_image(n.cartesianTransform, height =1).paint_uniform_color([1,0,0]) for n in imgNodes])
o3d.visualization.draw_geometries([joinedImages]+[pcdNode.resource])
```

Now the [COMPETITION](https://paperswithcode.com/datasets) is to align as many of the resources as possible. All you have to do is report your percentage of properly aligned imagery on the complete dataset.

![2.PNG](../assets/img/2.PNG)

